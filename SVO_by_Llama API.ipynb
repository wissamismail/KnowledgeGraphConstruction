{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2bb582-049b-469b-8ba7-33fad2f86767",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llamaapi -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3e31884-eb76-425e-bbda-6fed6f37d519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamaapi import LlamaAPI\n",
    "import json\n",
    "import os\n",
    "# Replace 'Your_API_Token' with your actual API token\n",
    "llama = LlamaAPI('LL-69WCQLo6Rh6ucWGD5jMhWcxeMJZsKikJWlBUfzVys7K8KJw9gKLbokgLxn7zudlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b280c63d-43c3-4ff7-bb65-7cd2e396b768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"created\": 1721132565,\n",
      "  \"model\": \"llama3-70b\",\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 78,\n",
      "    \"completion_tokens\": 76,\n",
      "    \"total_tokens\": 154\n",
      "  },\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Lllovely llhuman, llhappy llto llhear llfrom llyou! Llwhat llcan llI llhelp llyou llwith lloday? Llperhaps llwe llcan lllearn llabout llthe lllatest ll llama llfashion lltrends llor llfind llthe llbest llspots llfor llgrazing?\",\n",
      "        \"function_call\": null\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# API Request JSON Cell\n",
    "api_request_json = {\n",
    "  \"model\": \"llama3-70b\",\n",
    "  \"messages\": [\n",
    "    {\"role\": \"system\", \"content\": \"You are a llama assistant that talks like a llama, starting every word with 'll'.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi, happy llama day!\"},\n",
    "  ]\n",
    "}\n",
    "\n",
    "# Make your request and handle the response\n",
    "response = llama.run(api_request_json)\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c53d4ff7-935d-4706-9df6-04b1dfb647f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reqDesc = \"\"\"\n",
    "for every sentence(lit-x) that I will give you, I need to help me to return the SVO as Spacy do for this sentence, like this structure:\n",
    "{\n",
    "\"lit-1\": {\n",
    "      \"SVO_relationships\": [\n",
    "        {\n",
    "          \"subject\": \"the fake, country-wet freshness\",\n",
    "          \"verb\": \"evaporated\",\n",
    "          \"stem\": \"evaporate\",\n",
    "          \"object\": \"like the tail end of a sweet dream\"\n",
    "        },\n",
    "        {\n",
    "          \"subject\": \"the hot streets\",\n",
    "          \"verb\": \"wavered\",\n",
    "          \"stem\": \"waver\",\n",
    "          \"object\": \"in the sun\"\n",
    "        },\n",
    "        {\n",
    "          \"subject\": \"I\",\n",
    "          \"verb\": \"kept hearing\",\n",
    "          \"stem\": \"hear\",\n",
    "          \"object\": \"about the Rosenbergs over the radio and at the office\"\n",
    "        },\n",
    "        {\n",
    "          \"subject\": \"I\",\n",
    "          \"verb\": \"couldn't get\",\n",
    "          \"stem\": \"get\",\n",
    "          \"object\": \"them out of my mind\"\n",
    "        }\n",
    "      ],\n",
    "      \"total_SVOs\": 4\n",
    "  },\n",
    "\n",
    "  \"lit-2\": {...\n",
    "}\n",
    "are you ready?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72f3012d-3c73-4b39-9a4e-32adb8626888",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    \"literature\": \"Lit\",\n",
    "    \"medical-articles\": \"Med\",\n",
    "    \"moviescripts\": \"Mov\",\n",
    "    \"news-press-releases\": \"NPR\",\n",
    "}\n",
    "def iterate_category(category_name, category_prefix, error_log_path):\n",
    "    folder_path = f'E:/workspaces/PythonWS/Selenium-python/chatGPT/myDataset/{category_name}'\n",
    "    files = sorted(os.listdir(folder_path))[51:100]\n",
    "    all_data = {}\n",
    "    errors = []\n",
    "    output_json_temp = f'E:/workspaces/PythonWS/Selenium-python/chatGPT/myResult/Using_LLAMA3/{category_name}.json'\n",
    "    os.makedirs(os.path.dirname(output_json_temp), exist_ok=True)\n",
    "    with open(output_json_temp, 'w', encoding='utf-8') as json_file:\n",
    "        for idx, file_name in enumerate(files, start=1):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    text = file.read()\n",
    "                    req = text\n",
    "                    time.sleep(10)\n",
    "                    resp = make_gpt_request(req)\n",
    "\n",
    "                    api_request_json = {\"model\": \"llama3-70b\",\n",
    "                      \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": reqDesc},\n",
    "                    {\"role\": \"user\", \"content\": req},\n",
    "                      ]\n",
    "                        }\n",
    "                \n",
    "                    # Make your request and handle the response\n",
    "                    resp = llama.run(api_request_json)\n",
    "\n",
    "                    #print(resp)\n",
    "                    svos = resp\n",
    "                    if svos:\n",
    "                        all_data[f\"{category_prefix}-{idx}\"] = {\n",
    "                            \"SVO_relationships\": svos,\n",
    "                            \"total_SVOs\": len(svos)\n",
    "                        }\n",
    "                    else:\n",
    "                        errors.append(f\"No SVOs found in file {file_name} ({category_prefix}-{idx})\")\n",
    "                    print(all_data)\n",
    "                    json.dump(all_data, json_file, indent=4, ensure_ascii=False)\n",
    "            except Exception as e:\n",
    "                errors.append(f\"Error processing file {file_name} ({category_prefix}-{idx}): {str(e)}\")\n",
    "    output_json_path = f'E:/workspaces/PythonWS/Selenium-python/chatGPT/myResult/Using_LLAMA3/{category_name}.json'\n",
    "    os.makedirs(os.path.dirname(output_json_path), exist_ok=True)\n",
    "    with open(output_json_path, 'w', encoding='utf-8') as json_file2:\n",
    "        json.dump(all_data, json_file2, indent=4, ensure_ascii=False)\n",
    "    print(f\"SVOs for {category_name} saved to {output_json_path}\")\n",
    "\n",
    "    # Write errors to log file\n",
    "    with open(error_log_path, 'a', encoding='utf-8') as log_file:\n",
    "        for error in errors:\n",
    "            log_file.write(error + '\\n')\n",
    "    print(f\"Errors for {category_name} logged to {error_log_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f224586b-f6ea-4e80-9fde-1cccc89bf3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "literature\n",
      "SVOs for literature saved to E:/workspaces/PythonWS/Selenium-python/chatGPT/myResult/Using_LLAMA3/literature.json\n",
      "Errors for literature logged to E:/workspaces/PythonWS/Selenium-python/chatGPT/myDataset/myResult/Using_LLAMA3/error_log.txt\n",
      "medical-articles\n",
      "SVOs for medical-articles saved to E:/workspaces/PythonWS/Selenium-python/chatGPT/myResult/Using_LLAMA3/medical-articles.json\n",
      "Errors for medical-articles logged to E:/workspaces/PythonWS/Selenium-python/chatGPT/myDataset/myResult/Using_LLAMA3/error_log.txt\n",
      "moviescripts\n",
      "SVOs for moviescripts saved to E:/workspaces/PythonWS/Selenium-python/chatGPT/myResult/Using_LLAMA3/moviescripts.json\n",
      "Errors for moviescripts logged to E:/workspaces/PythonWS/Selenium-python/chatGPT/myDataset/myResult/Using_LLAMA3/error_log.txt\n",
      "news-press-releases\n",
      "SVOs for news-press-releases saved to E:/workspaces/PythonWS/Selenium-python/chatGPT/myResult/Using_LLAMA3/news-press-releases.json\n",
      "Errors for news-press-releases logged to E:/workspaces/PythonWS/Selenium-python/chatGPT/myDataset/myResult/Using_LLAMA3/error_log.txt\n"
     ]
    }
   ],
   "source": [
    "# Error log path\n",
    "error_log_path = 'E:/workspaces/PythonWS/Selenium-python/chatGPT/myDataset/myResult/Using_LLAMA3/error_log.txt'\n",
    "os.makedirs(os.path.dirname(error_log_path), exist_ok=True)\n",
    "# Process each category\n",
    "for category, prefix in categories.items():\n",
    "    print(category)\n",
    "    iterate_category(category, prefix, error_log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24db52ce-561d-4c21-9c8c-1e99aecc9a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_request_json = {\n",
    "  \"messages\": [\n",
    "    {\"role\": \"user\", \"content\": \"Extract the desired information from the following passage.:\\n\\nHi!\"},\n",
    "  ],\n",
    "  \"functions\": [\n",
    "        {'name': 'information_extraction',\n",
    "         'description': 'Extracts the relevant information from the passage.',\n",
    "         'parameters': {\n",
    "             'type': 'object',\n",
    "             'properties': {\n",
    "                 'sentiment': {\n",
    "                    'title': 'sentiment',\n",
    "                    'type': 'string',\n",
    "                    'description': 'the sentiment encountered in the passage'\n",
    "                    },\n",
    "                 'aggressiveness': {\n",
    "                    'title': 'aggressiveness',\n",
    "                    'type': 'integer',\n",
    "                    'description': 'a 0-10 score of how aggressive the passage is'\n",
    "                    },\n",
    "                 'language': {\n",
    "                    'title': 'language',\n",
    "                    'type': 'string',\n",
    "                    'description': 'the language of the passage'\n",
    "                    }\n",
    "             },\n",
    "             'required': ['sentiment', 'aggressiveness', 'language']\n",
    "         }\n",
    "      }\n",
    "    ],\n",
    "  \"stream\": False,\n",
    "  \"function_call\": {\"name\": \"information_extraction\"},\n",
    "}\n",
    "\n",
    "# Make your request and handle the response\n",
    "response = llama.run(api_request_json)\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb8c84a-d97c-4687-bb73-ad15508fac78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
